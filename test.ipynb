{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "<|im_start|>system\n",
      "The producers in all ecosystems are plants.\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "TOGETHER_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=TOGETHER_API_KEY,\n",
    "  base_url='https://api.together.xyz/v1',\n",
    ")\n",
    "# Get prompt from data\n",
    "prompt = \"Which statement best explains why photosynthesis is the foundation of most food webs?\"\n",
    "choices = [\"Most ecosystems are found on land instead of in water.\", \"Sunlight is the source of energy for nearly all ecosystems.\", \"Carbon dioxide is more available than other gases.\", \"The producers in all ecosystems are plants.\"]\n",
    "\n",
    "messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant, you will be given a question and 4 answer choices, choose the correct answer choice\",  # could change this later\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{prompt}\\n\\n Please choose the best answer among these options: {', '.join(choices)}\",  # Include choices in the prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Make API call to Together API\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"meta-llama/Llama-2-70b-hf\",\n",
    "    max_tokens = 1024,\n",
    "    stop = \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "print(\"----------\")\n",
    "print(chat_completion.choices[0].message.content)\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The producers in all ecosystems are plants.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the answer from the response\n",
    "answer = chat_completion.choices[0].message.content.split(\"\\n\")[-1]\n",
    "print(answer)\n",
    "predictedidx = choices.index(answer)\n",
    "predictedidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "The producers in all ecosystems are plants.\n",
      "The producers in all ecosystems are plants.\n",
      "The producers in all ecosystems are plants.\n",
      "<|im_start|>system\n",
      "The correct answer is breathing mask\n",
      "The correct answer is breathing mask\n",
      "breathing mask\n",
      "<|im_start|>system\n",
      "The correct answer is ovary cells\n",
      "The correct answer is ovary cells\n",
      "ovary cells\n",
      "<|im_start|>system\n",
      "The correct answer is soft\n",
      "The correct answer is soft\n",
      "soft\n",
      "<|im_start|>system\n",
      "The correct answer is: a network of interacting positive and negative particles\n",
      "The correct answer is: a network of interacting positive and negative particles\n",
      "a network of interacting positive and negative particles\n",
      "<|im_start|>system\n",
      "light-year.\n",
      "light-year.\n",
      "light-year.\n",
      "<|im_start|>system\n",
      "The correct answer is: wash hands\n",
      "The correct answer is: wash hands\n",
      "wash hands\n",
      "<|im_start|>system\n",
      "The correct answer is grams.\n",
      "\n",
      "The correct answer is grams.\n",
      "grams\n",
      "<|im_start|>system\n",
      "food.\n",
      "food.\n",
      "food.\n",
      "<|im_start|>system\n",
      "The correct answer is Xylem carries water from the roots to the leaves.\n",
      "\n",
      "The correct answer is Xylem carries water from the roots to the leaves.\n",
      "Xylem carries water from the roots to the leaves.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('C:/Users/nyc8p/OneDrive/Documents/GitHub/AI-Dive/')\n",
    "from ai.dive.models.togetherai import TogetherAI\n",
    "\n",
    "TOGETHER_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "model_name = \"meta-llama/Llama-2-70b-hf\"\n",
    "model = TogetherAI(model_name)\n",
    "\n",
    "data = pd.read_json('arc_easy_test.jsonl', lines = True)\n",
    "# model.predict(data.iloc[7])\n",
    "for i in range(10):\n",
    "    model.predict(data.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                               Mercury_417466\n",
       "prompt        Which statement best explains why photosynthes...\n",
       "choices       [Sunlight is the source of energy for nearly a...\n",
       "answer_idx                                                    0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:06<00:49,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The producers in all ecosystems are plants.\n",
      "Error processing item 0: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:17<01:03,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breathing mask\n",
      "Error processing item 1: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:18<00:32,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovary cells\n",
      "Error processing item 2: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:24<00:28,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft\n",
      "Error processing item 3: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:25<00:15,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a network of interacting positive and negative particles\n",
      "Error processing item 4: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:26<00:08,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light-year.\n",
      "Error processing item 5: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:27<00:04,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wash hands\n",
      "Error processing item 6: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:28<00:02,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grams\n",
      "Error processing item 7: 'answer_idx'\n",
      "trying to call predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:29<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food.\n",
      "Error processing item 8: 'answer_idx'\n",
      "Saving 0 results to test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['id', 'prompt', 'choices', 'answer_idx', 'predicted_idx'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m saver \u001b[38;5;241m=\u001b[39m Saver(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, output_keys\u001b[38;5;241m=\u001b[39moutput_keys, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     21\u001b[0m diver \u001b[38;5;241m=\u001b[39m Diver(model, dataset, saver\u001b[38;5;241m=\u001b[39msaver)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mdiver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\OneDrive\\Documents\\GitHub\\AI-Dive\\ai\\dive\\diver.py:33\u001b[0m, in \u001b[0;36mDiver.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Save at the end\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\OneDrive\\Documents\\GitHub\\AI-Dive\\ai\\dive\\saver.py:24\u001b[0m, in \u001b[0;36mSaver.save\u001b[1;34m(self, results)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\OneDrive\\Documents\\GitHub\\AI-Dive\\ai\\dive\\saver.py:34\u001b[0m, in \u001b[0;36mSaver.save_csv\u001b[1;34m(self, results)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Select only the output keys specified in their order\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     36\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\anaconda3\\envs\\oxennew\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\anaconda3\\envs\\oxennew\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nyc8p\\anaconda3\\envs\\oxennew\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['id', 'prompt', 'choices', 'answer_idx', 'predicted_idx'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from ai.dive.data.togetheraipromptrepeater import togetheraipromptrepeater\n",
    "from ai.dive.models.togetherai import TogetherAI\n",
    "from ai.dive.diver import Diver\n",
    "from ai.dive.saver import Saver\n",
    "model_name = \"meta-llama/Llama-2-70b-hf\"\n",
    "model = TogetherAI(model_name)\n",
    "\n",
    "#arc-easy dataset jsonl file from directory (arc_easy_test.jsonl)\n",
    "# Load dataset from JSONL file\n",
    "#prompt template\n",
    "dataset = togetheraipromptrepeater(\n",
    "    file='test.jsonl',\n",
    "    template=\"You are an AI assistant, you will be given a question and 4 answer choices, output the correct answer choice with no other text\"\n",
    ")\n",
    "# dataset = PromptTemplateFiller(\n",
    "#     file=args.dataset,\n",
    "# )\n",
    "\n",
    "output_keys = ['id', 'prompt', 'choices', 'answer_idx', 'predicted_idx']\n",
    "saver = Saver('test.csv', output_keys=output_keys, format=\"csv\", save_every=10)\n",
    "diver = Diver(model, dataset, saver=saver)\n",
    "diver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oxennew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
